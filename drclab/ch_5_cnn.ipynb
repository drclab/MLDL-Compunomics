{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Say our input is a 32-pixel by 32-pixel grayscale image where every pixel in the grayscale image is represented by a value between 0 to 255. Here, 0 indicates black, 255 represents indicates white, and any values between 0 and 255 indicate various shades of gray. Since the grayscale image has only one channel, the image can be represented as 32 x 32 x 1 = 1024, and consequently has 1,024 nodes in the input layer of the FNN. Suppose our next layer (hidden layer) has 100 nodes, and since this should be fully connected to the previous layer, we will have 1,024 x 100 = 102,400 weights for the first 2 layers (input and the first hidden layer). Since we know by now that a complex problem such as this requires multiple hidden layers in the FNN to map the inputs and the outputs in the training data to generate an accurate model, as such, we now have a problem with too many parameters in the FNN, which makes the training process very complex because of the increased dimension space. In addition, it makes the learning process slower, uses more resources, and increases the chances of overfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If we are to use the color images, the problem is further compounded because the color images have 3 channels (red, green, and blue) where each color is represented by a channel, and so in total there are 3 values and 32 x 32 x 3 = 3,072 values. Correspondingly, the number of weights for such an image is 3,072 x 100 = 3,072,000. FNNs cannot scale to handle these kinds of images, so there needs to be a better scalable architecture. Another limitation of FNNs with image data is that the 2D image is converted to a 1D flattened vector, and so the spatial relationship of the different pixels is completely lost. So, there needs to be a better NN architecture that can keep spatial relationships and process unstructured data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs are a special type of NN architecture that is widely applied for unstructured data such as images, audio, video, text, and so on. CNNs are great networks for analyzing data with spatial dependencies such as images, audio, DNA sequences, and so on. They work well on DNA sequence data. The main applications of CNNs include image classification, NLP, signal processing, and speech recognition. CNNs have a series of convolutional layers, which allows them to automatically extract hierarchical patterns in the data. CNNs are currently being used in genomics tasks where local patterns are very important to the outcome—for example, the detection of conserved motifs to identify blocks of genes in a DNA sequence or binding sites of a protein such as a transcription factor (TF). Let’s dive deep into the wonderful world of CNNs in the following sections."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781804615447/files/image/B18958_05_002.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A convolutional layer consists of multiple filters (also called kernels) that are nothing but the matrix of weights—for example, a filter of size 9 (3 by 3) that is initialized with values randomly between 0 to 10."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next, convolution is done by placing this filter at the top-left corner in the case of the image and taking the dot product of the filter values and the input values of the pixel (remember—pixel values range from 0 to 255, but they are normalized to keep the values between 0 to 1) to calculate a feature map, and we will take a step size (stride) of n=1 to the right."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is repeated until we reach the top-right corner of the image, and then we start over again from one down cell from the left of the image until we finish scanning the whole image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While convolving the filter, we calculate the dot product of the weights on the filter with the input values. For example, as shown in Figure 5.2, the input size of 5 by 5 (25 in total) is being scanned by a filter of size 9 (3 by 3), and the dot product of the filter values and the input values of the pixel is being calculated in the output array:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the case of a DNA sequence as an input, after creating a one-hot encoding (Figure 5.3), the convolutions are performed similar to image data. Each filter chosen will act as a sliding window."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781804615447/files/image/B18958_05_003.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next layer after the convolution layer is the pooling layer, which reduces the number of parameters, memory usage, and computational cost, and prevents overfitting in the network progressively (Figure 5.4). It is quite normal to have pooling layers between multiple convolutional layers. The pooling layer operates as a downsampling layer, and while doing so, computes either an average or a maximum value for a specified filter size and stride (slide is nothing but a sliding window size):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781804615447/files/image/B18958_05_004.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781804615447/files/image/B18958_05_006.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781804615447/files/image/B18958_05_007.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781804615447/files/image/B18958_05_008.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "There is also label encoding in which each nucleotide (A,G,C,T) is represented by a unique index thereby preserving the positional information. For example A=1, G=2, C=3, and T=4. Let’s try to understand why a CNN architecture is great for genomics problems using cancer prediction from Single nucleotide polymorphisms (SNP) variants from multiple patient samples as an example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the case of using FNN for cancer prediction, the first layer receives the SNP variants as input, and the weighted sum of each input value plus the “bias” (constant) is then passed through a non-linear function such as ReLu. This process repeats in the subsequent hidden layers until it reaches the output layer where it is transformed via sigmoid or softmax activation function to produce the hidden neurons output value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### . Although FNNs are powerful for this example, they are certainly not suitable for spatial or temporal datasets, and in genomics, there are several problems that are either spatial or temporal, and predicting cancer from SNPs is one of them. CNNs can address these issues. In the case of cancer prediction from the SNP data problem, SNPs are distributed according to a particular space pattern. So, a convolutional operation with predefined width and strides is performed on the input data. In this example (Figure 5.9), the convolutional operation is done using a kernel size of 1 by 3 and with a stride of 1. After multiple convolutions in one or more convolutional layers, the next layer is the max pooling layer, which takes the maximum of all values for each of those positions from kernel outputs using a predefined filter size. Pooling layers are then flattened and connected to a non-linear fully connected layer and finally to an output layer that has a binary class (cancer or no cancer) (Figure 5.9):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781804615447/files/image/B18958_05_009.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFs are DNA- and RNA binding proteins that play a crucial role in gene regulation. Knowing the binding sites of these DNA- and RNA-binding proteins would help us to develop models and can help identify disease-causing variants. One way to infer the sequence specificities of these proteins is through position weight matrices (PWMs), which can be used to scan the entire genome to identify potential binding sites of these DNA- and RNA-binding proteins. In addition, DNA- and RNA-binding protein specificities are measured by several high-throughput assays such as PBM, SELEX, and the most popular ChIP- and CLIP-seq techniques. Some of the challenges associated with this data are that the raw data comes in several different quantitative forms, the data is often extremely huge, and each data generation methodology suffers from artifacts, biases, and limitations that hinder the identification of binding sites. DL techniques show more promise in capturing sequence specificities of these binding proteins. [DeepBind](drclab/retrieve.pdf) is a CNN architecture that was built to predict DNA- and RNA-binding protein binding sites in the genome. It takes in noisy experimental data and outputs a binding affinity of a DNA- or RNA-binding protein to indicate how likely it is that the TF will bind to the sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepBind takes in a set of raw sequences with lengths ranging from 14 to 101 base pairs, along with an experimentally determined binding value as a label or target. From this data, it calculates the binding score in four stages—the convolutional stage, which scans the sequences with a set of motif detectors (4xm matrices) such as PWMs. The next is the rectification stage, which isolates any patterns by shifting responses of the motif detector and clamping any negative values to 0 using the ReLu activation function (remember—ReLu takes in a value and gives either 0 or the maximum of the value, whichever is the greatest). Following the rectification is the pooling stage, where the model calculates both the average and maximum value for each motif detector. The max pooling will help the model get the longer motifs or patterns, whereas the average pooling will help the model pick up the combined effect of shorter motifs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pooled values are then flattened and fed into the fully connected layer (non-linear NN) to produce the scores. The rest of the steps are typical of any FNN, which is to use backpropagation, cross-validation, and so on to optimize the weights and improve the model accuracy. The optimized DeepBind model is evaluated on test data to predict binding affinities and model performance using metrics such as AUC. Using DeepBind, you can now simply change the nucleotide position of a protein of interest and see how that affects the binding affinity of a TF in terms of positive or negative binding. Since DeepBind can find relationships between mutations and the dishes that cannot be inferred from traditional methods, researchers have used DeepBind to see where certain mutations in the cholesterol gene can disrupt the binding affinity of a TF."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepInsight\n",
    "\n",
    "[DeepInsight]('drclab/s41598-019-47765-6.pdf) is a CNN model that was built to extract features from genomics data. The idea of DeepInsight is simple. It takes non-image data such as genomics, transforms it into image data, and then feeds it into a CNN for classification or prediction depending on the problem. Instead of feature extraction and selection for collected samples ( samples x  features), DeepInsight finds a way of arranging closely related features into neighboring regions ( features x  samples), and all dissimilar features are kept further apart with the goal of learning complex relationships and interactions. Arranging similar elements together is a powerful method for uncovering hidden mechanisms such as pathways in biological systems. This approach of clustering similar features is more powerful than handling each feature separately, which ignores the neighborhood information that is key for spatial and temporal datasets. With this simple idea, it can transform any non-image data into feature map images, which can be a friendly representation of samples to a CNN architecture."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepChrome\n",
    "\n",
    "Among several factors that control transcriptional regulation, histone modification is the primary factor. Histone nucleosome proteins and histone modification through methylation is a very common gene regulatory mechanism. Understanding of the combinatorial effects of histone modification and gene regulation can help in developing epigenetic drugs for cancer. Researchers are interested in inferring the gene expression from methylated data, and so multiple computational models, both rule-based, which try to capture the relationships between histone modification and gene expression, and ML models such as linear regression, support vector machines (SVM), and Random Forest, have been proposed for gene expression predictions based on histone modification. However, neither of these methods have been successful. DeepChrome (https://academic.oup.com/bioinformatics/article/32/17/i639/2450757) is a CNN-based architecture that was designed to capture the interactions among histone modifications and use that to predict gene expression. If you recall, we have seen an example of methylation prediction using manually extracted features in Chapter 4, Deep Learning for Genomics. DeepChrome, allows automatic extraction off complex interactions or most important features without us manually extracting the same as we have done before.\n",
    "\n",
    "DeepVariant\n",
    "\n",
    "NGS technologies have allowed scientists and clinicians to produce sequencing data rapidly, cheaply, and at scale and apply it broadly to fields such as health, agriculture, and ecology. Accurate detection of genetic variants (SNPs and indels) from sequencing data is important for scientists and clinicians for disease detection, identifying genetic disorders, and making discoveries. DNA sequencing of genomes to identify genetic variants involves two key steps:\n",
    "\n",
    "- Sequencing of the samples, which generates relatively short pieces of DNA (reads)\n",
    "A variant caller that maps the reads against the known reference to identify where and how a sample’s genome sequence is different from a reference genome\n",
    "The current variant callers often struggle to accurately identify the correct variants and, in the process, generate lots of false-positive and false-negative variants. Accuracy of the variant detection is important because a false-negative variant indicates missing the causal variant for a disorder while the opposite (a false positive) means identifying the wrong variant. DeepVariant (https://www.nature.com/articles/nbt.4235) is a CNN-based framework that converts variant identification problems into image classification problems. It takes the input data, which is aligned sequences (reads) to the reference, and constructs multichannel images representing some aspect of the sequence—for example, one channel can be read base, the second channel is the mapping quality, and the third channel is read supports allele, and so on. Finally, DeepVariant generates one of three genotype likelihoods (0, 1, or 2) of given alternate alleles in each sample. Using this unique design, DeepVariant outperformed state-of-the-art variant detection tools. The model can be used across other genomes allowing nonhuman sequencing projects to benefit other genome projects. In addition, DeepVariant can be leveraged for other sequencing technologies and experimental designs highlighting the importance of this architecture.\n",
    "\n",
    "CNNC\n",
    "A CNN for coexpression (CNNC) (https://www.biorxiv.org/content/10.1101/365007v2) is a supervised CNN architecture that uses gene expression data to understand relationships between genes. Each pair of genes is represented as a histogram, and a CNN model is trained with training examples that have both positive and negative samples. Some examples of these include known targets of a TF, known pathways for a specific biological process, known disease genes, and so on. First, the gene expression levels from each pair of genes are transformed into 32 x 32 normalized empirical probability distribution function (NEPDF) matrices. Next, each NEPDF matrix is fed into the network as an input. The other input types can be DNase-Seq, PWM data, and so on. After going through the convolutions, finally, the output of a CNNC can either be a binary classification or a multi-class classification.\n",
    "\n",
    "Summa"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
